{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e450b4c4-d46a-4f29-8cf5-4b0829bd1cff",
   "metadata": {},
   "source": [
    "#### Loads all OpenSecrets bulk datasets ####\n",
    "(With the exception of crp_ids.xlsx, which has many sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bccc241-4dd4-478e-bda4-ca6f3c20563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data module...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83e3a5a6-7014-4d98-ba38-3a9e45a1af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(filepath, nrows=1e100, headers=None, n_expected_fields=None, show_errs=True, err_verbose=False):\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    # Must have a way to assign headers and expected fields.\n",
    "    if (n_expected_fields == None) & (headers == None):\n",
    "        raise ValueError(\"Invalid arguments: provide either headers or n_expected_fields, or both.\")\n",
    "    else:\n",
    "        n_expected_fields = len(headers)\n",
    "\n",
    "    # Process all the lines.\n",
    "    i = 1\n",
    "    bad_lines_count = 0\n",
    "    processed_lines = []\n",
    "    lines = data.splitlines()\n",
    "    progress_interval = int(len(lines)/5)\n",
    "    for line in lines:\n",
    "        if i > nrows:\n",
    "            break;\n",
    "        \n",
    "        print(f\"Reading line {i} of {len(lines)}...\") if i % progress_interval == 0 else None\n",
    "\n",
    "        # Check for bad lines.\n",
    "        field_count = len(line.split(','))\n",
    "        if field_count != n_expected_fields:\n",
    "            bad_lines_count += 1\n",
    "            if show_errs == True:\n",
    "                print(f\"Bad line {i}\")\n",
    "                if err_verbose == True:\n",
    "                    print(f\"{line}\")\n",
    "\n",
    "        # Format as csv.\n",
    "        processed_line = re.sub(r'\\|([^|]*)\\|', r'\"\\1\"', line)\n",
    "        processed_lines.append(processed_line)\n",
    "        i += 1\n",
    "\n",
    "    rel_path = os.path.dirname(filepath)\n",
    "    filename_w_ext = os.path.basename(filepath)\n",
    "    filename_wo_ext = os.path.splitext(filename_w_ext)[0]\n",
    "    \n",
    "    output_filepath = rel_path + '/' + filename_wo_ext + '.csv'\n",
    "    \n",
    "    # Save as a csv file.\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as file:\n",
    "        if headers:\n",
    "            # Append data source to headers, separated by double underscore.\n",
    "            headers_processed = []\n",
    "            for header in headers:\n",
    "                headers_processed.append(str(header) + '__' + filename_wo_ext)\n",
    "            file.write(','.join(headers_processed) + '\\n')\n",
    "        file.write('\\n'.join(processed_lines))\n",
    "    \n",
    "    print(f\"Processed data saved as {output_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee32c2e-fd39-48a0-bd1b-7ff4f977a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"...data module loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3b204-6445-4161-b826-8a578b3b87ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
