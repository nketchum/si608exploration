{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7afacead-3850-4449-8769-58ce13d7092c",
   "metadata": {},
   "source": [
    "# SI 608 Project â€“ Workspace\n",
    "<span style=\"font-size: 18px;\">General scratchpad workspace that preloads all the dataframes.</span>\n",
    "<br>See <code>./modules</code> to review how libraries are installed and imported, as well as where the data is loaded, cleaned, and formatted. This is only here as a helpful tool, make a copy and do whatever you'd like. Or don't use this at all if that's preferable.\n",
    "\n",
    "[OpenSecrets Data Dictionary Index](../../docs/open_source_data_dictionary.md)\n",
    "<br><small><em>(View the index with markdown preview)</em></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaecaf6-03ea-4232-966a-3ffe9bd15529",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Run these cells first to load global functions and variables, augment enivronment, and produce and load primary datasets for this project, overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844f9c6-ac9b-424c-a465-f4f3eb5e687c",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "Configure frequently modified behaviors in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4774c-9011-4819-81fc-342611db2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT THIS IN .env?\n",
    "DISPLAY_DF = True # for showdf() -> df.head()\n",
    "SAVE_DF = True # for to_csv() -> pd.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49c737-37ae-4c27-9f68-dfd69c537631",
   "metadata": {},
   "source": [
    "#### Init globals\n",
    "Init file contains global variables and helper functions used throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe3e1f-9c7c-4629-b11f-0d84cf0b7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95228d13-837b-40a2-8cd4-d3e80f87513e",
   "metadata": {},
   "source": [
    "#### Local env\n",
    "Contain things like API keys that should be excluded from the public repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8048ae-debc-4512-a5b6-d1a800d7b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = load_env_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c7e18-5bff-4623-8dc6-72f74f8c06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONGRESS_API_KEY = env_vars['CONGRESS_API_KEY']\n",
    "CONGRESS_API_URL = env_vars['CONGRESS_API_URL']\n",
    "\n",
    "print(f\"CONGRESS_API_KEY: {CONGRESS_API_KEY}, CONGRESS_API_URL: {CONGRESS_API_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d727f9-82e1-472d-bab1-3c8c8664553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONGRESS_NUM = 116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743863c-9450-4e0a-abe7-07cb9fc1e480",
   "metadata": {},
   "source": [
    "## Data\n",
    "From OpenSecrets.org bulk data collection. Contains data from IRS and the FEC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7671134-874c-49d0-b74e-30804f9f473f",
   "metadata": {},
   "source": [
    "### 527 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a40058-51ad-4ff6-bfab-fa6f77fe5067",
   "metadata": {},
   "source": [
    "#### cmtes527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f59f48-f867-4757-8ac8-d3413afc30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OpenSecrets Data Definition: 527 Committees\n",
    "# # https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20527%20Cmtes.htm\n",
    "# try:\n",
    "#     df_cmtes527.head()\n",
    "# except NameError:\n",
    "#     print(\"Creating dataframe...\")\n",
    "#     df_cmtes527 = pd.read_csv('../../data/open_secrets/527/cmtes527.txt', \n",
    "#                                quotechar='|', \n",
    "#                                sep=',', \n",
    "#                                encoding='ISO-8859-1',\n",
    "#                                header=None,\n",
    "#                                names=['cycle__cmtes527', 'rpt__cmtes527', 'ein__cmtes527', 'crp527name__cmtes527', 'affiliate__cmtes527', 'ultorg__cmtes527', \n",
    "#                                       'recipcode__cmtes527', 'cmteid__cmtes527', 'cid__cmtes527', 'eccmteid__cmtes527', 'party__cmtes527', \n",
    "#                                       'primcode__cmtes527', 'source__cmtes527', 'ffreq__cmtes527', 'ctype__cmtes527', 'csource__cmtes527', 'viewpt__cmtes527',\n",
    "#                                       'comments__cmtes527', 'state__cmtes527'])\n",
    "#     print(\"Finished.\")\n",
    "\n",
    "# showdf(df_cmtes527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3adbc-e8d7-4355-9834-274bcd3cefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showdf(df_cmtes527)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660cb9e-73b8-4d29-8d13-d0217ee47688",
   "metadata": {},
   "source": [
    "#### expends527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4886a-fce0-4861-9cd7-e1c6fae79b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OpenSecrets Data Dictionary 527 Expenditure Data - from IRS Form 8872B\n",
    "# # https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20527%20Expenditures.htm\n",
    "# try:\n",
    "#     df_expends527.head()\n",
    "# except NameError:\n",
    "#     print(\"Creating dataframe...\")\n",
    "#     df_expends527 = pd.read_csv('../../data/open_secrets/527/expends527.txt', \n",
    "#                                quotechar='|', \n",
    "#                                sep=',', \n",
    "#                                encoding='ISO-8859-1',\n",
    "#                                header=None,\n",
    "#                                names='rpt__expends527', 'formid__expends527', 'schbid__expends527', 'orgname__expends527', 'ein__expends527', 'recipient__expends527', \n",
    "#                                      'recipientcrp__expends527', 'amount__expends527', 'date__expends527', 'expcode__expends527', 'source__expends527', \n",
    "#                                      'purpose__expends527', 'addr1__expends527', 'addr2__expends527', 'city__expends527', 'state__expends527', 'zip__expends527',\n",
    "#                                      'employer__expends527', 'occupation__expends527'])\n",
    "#     print(\"Finished.\")\n",
    "\n",
    "# showdf(df_expends527)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06120a9a-1840-4b06-9fb3-e47197395c4b",
   "metadata": {},
   "source": [
    "#### rcpts527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96954ed3-98b2-4ab8-8629-4a98741f962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OpenSecrets Data Dictionary 527 Contribution Data - from IRS Form 8872A\n",
    "# # https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20527%20Receipts.htm\n",
    "# try:\n",
    "#     df_rcpts527.head()\n",
    "# except NameError:\n",
    "#     print(\"Creating dataframe...\")\n",
    "#     df_rcpts527 = pd.read_csv('../../data/open_secrets/527/rcpts527.txt', \n",
    "#                                quotechar='|', \n",
    "#                                sep=',', \n",
    "#                                encoding='ISO-8859-1',\n",
    "#                                header=None,\n",
    "#                                names=['id__rcpts527', 'rpt__rcpts527', 'formid__rcpts527', 'schaid__rcpts527', 'contribid__rcpts527', 'contrib__rcpts527', \n",
    "#                                       'amount__rcpts527', 'date__rcpts527', 'orgname__rcpts527', 'ultorg__rcpts527', 'realcode__rcpts527', \n",
    "#                                       'recipid__rcpts527', 'recipcode__rcpts527', 'party__rcpts527', 'recipient__rcpts527', 'city__rcpts527', 'state__rcpts527',\n",
    "#                                       'zip__rcpts527', 'zip4__rcpts527', 'pmsa__rcpts527', 'employer__rcpts527', 'occupation__rcpts527', 'ytd__rcpts527', 'gender__rcpts527', 'source__rcpts527'])\n",
    "#     print(\"Finished.\")\n",
    "\n",
    "# showdf(df_rcpts527)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da33756-f35b-4d7c-8931-558884389db3",
   "metadata": {},
   "source": [
    "### Campaign Finance 18 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e599e17-fc9b-4124-af26-630fe07957d3",
   "metadata": {},
   "source": [
    "#### cands18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cab31-9bef-40f7-8c7c-d468bb649787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition: Candidates\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20Candidates%20Data.htm\n",
    "try:\n",
    "    df_cands18.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_cands18 = pd.read_csv('../../data/open_secrets/CampaignFin18/cands18.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['cycle__cands18', 'feccandid__cands18', 'cid__cands18', 'firstlastp__cands18', 'party__cands18', 'distidrunfor__cands18', \n",
    "                                      'distidcurr__cands18', 'currcand__cands18', 'cyclecand__cands18', 'crpico__cands18', 'recipcode__cands18', \n",
    "                                      'nopacs__cands18'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "# Remove party labels from names: '3', 'R', 'D', 'I', 'L', 'U', 'i'\n",
    "df_cands18['firstlast__cands18'] = df_cands18['firstlastp__cands18'].apply(\n",
    "    lambda x: x.replace(\" (3)\", \"\").replace(\" (R)\", \"\").replace(\" (D)\", \"\").replace(\" (I)\", \"\").replace(\" (L)\", \"\").replace(\" (U)\", \"\").replace(\" (i)\", \"\") if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "showdf(df_cands18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e3d4e-aa8f-4aa8-aa68-652f966a10f1",
   "metadata": {},
   "source": [
    "#### cmtes18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78614302-9b57-4f64-9b76-796d436c7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Table Definition: Committee table\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20for%20Cmtes.htm\n",
    "try:\n",
    "    df_cmtes18.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_cmtes18 = pd.read_csv('../../data/open_secrets/CampaignFin18/cmtes18.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['cycle__cmtes18', 'cmteid__cmtes18', 'pacshort__cmtes18', 'affiliate__cmtes18', 'ultorg__cmtes18', 'recipid__cmtes18', \n",
    "                                      'recipcode__cmtes18', 'feccandid__cmtes18', 'party__cmtes18', 'primcode__cmtes18', 'source__cmtes18', 'sensitive__cmtes18',\n",
    "                                      'foreign__cmtes18', 'active__cmtes18'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_cmtes18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643cb0c5-c561-416c-9c18-42b586890dcd",
   "metadata": {},
   "source": [
    "#### pac_other18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fda588-846c-4d7e-b8ea-4c789dc51a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OpenSecrets Data Definition for PAC to PAC Data (Pac_other table)\n",
    "# # https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20PAC%20to%20PAC%20Data.htm\n",
    "# try:\n",
    "#     df_pac_other18.head()\n",
    "# except NameError:\n",
    "#     print(\"Creating dataframe...\")\n",
    "#     df_pac_other18 = pd.read_csv('../../data/open_secrets/CampaignFin18/pac_other18.txt', \n",
    "#                                quotechar='|', \n",
    "#                                sep=',', \n",
    "#                                encoding='ISO-8859-1',\n",
    "#                                header=None,\n",
    "#                                names=['cycle__pac_other18', 'fecrecno__pac_other18', 'filerid__pac_other18', 'donorcmte__pac_other18', 'contriblendtrans__pac_other18', 'city__pac_other18', 'state__pac_other18', \n",
    "#                                       'zip__pac_other18', 'fecoccemp__pac_other18', 'primcode__pac_other18', 'date__pac_other18', 'amount__pac_other18', 'recipid__pac_other18', 'party__pac_other18', 'otherid__pac_other18',\n",
    "#                                       'recipcode__pac_other18', 'recipprimcode__pac_other18', 'amend__pac_other18', 'report__pac_other18', 'pg__pac_other18', 'microfilm__pac_other18', 'type__pac_other18',\n",
    "#                                       'realcode__pac_other18', 'source__pac_other18'])\n",
    "#     print(\"Finished.\")\n",
    "\n",
    "# showdf(df_pac_other18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03f07c-3b52-4e39-ae2d-11a7337e0feb",
   "metadata": {},
   "source": [
    "#### pacs18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be3ea0-c0d0-4d9f-8fe7-b9041cdbd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition: PAC table (PACs to Candidates)\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20for%20PAC%20to%20Cands%20Data.htm\n",
    "try:\n",
    "    df_pacs18.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_pacs18 = pd.read_csv('../../data/open_secrets/CampaignFin18/pacs18.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['cycle__pacs18', 'fecrecno__pacs18', 'pacid__pacs18', 'cid__pacs18', 'amount__pacs18', 'date__pacs18', 'realcode__pacs18', \n",
    "                                      'type__pacs18', 'di__pacs18', 'feccandid__pacs18'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_pacs18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b6e92-3371-4343-b43a-1d43a7539d18",
   "metadata": {},
   "source": [
    "#### indivs18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fe7df-f177-409f-848d-fe104f009212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OpenSecrets Data Definition: Individual Contribution Data\n",
    "# # https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20for%20Individual%20Contribution%20Data.htm\n",
    "# try:\n",
    "#     df_indivs18.head()\n",
    "# except NameError:\n",
    "#     print(\"Creating dataframe...\")\n",
    "#     df_indivs18 = pd.read_csv('../../data/open_secrets/CampaignFin18/indivs18.txt', \n",
    "#                                quotechar='|', \n",
    "#                                sep=',', \n",
    "#                                encoding='ISO-8859-1',\n",
    "#                                header=None,\n",
    "#                                names=['cycle__indivs18', 'fectransid__indivs18', 'contribid__indivs18', 'contrib__indivs18', 'recipid__indivs18', 'orgname__indivs18', \n",
    "#                                       'ultorg__indivs18', 'realcode__indivs18', 'date__indivs18', 'amount__indivs18', 'street__indivs18', 'city__indivs18', 'state__indivs18',\n",
    "#                                       'zip__indivs18', 'recipcode__indivs18', 'type__indivs18', 'cmteid__indivs18', 'otherid__indivs18', 'gender__indivs18', 'microfilm__indivs18',\n",
    "#                                       'occupation__indivs18', 'employer__indivs18', 'source__indivs18'])\n",
    "#     print(\"Finished.\")\n",
    "\n",
    "# showdf(df_indivs18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566f524-4260-4b8b-8b9f-87b3439e18f7",
   "metadata": {},
   "source": [
    "### Expends18 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e36b5e-1eb2-469e-8be2-263a30fa43e2",
   "metadata": {},
   "source": [
    "#### expends18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda8166-eb35-4243-815d-3db2377b3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OpenSecrets Data Dictionary for Expenditure Data - from FEC electronic filings\n",
    "# # https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20Expenditures.htm\n",
    "# try:\n",
    "#     df_expends18.head()\n",
    "# except NameError:\n",
    "#     print(\"Creating dataframe...\")\n",
    "#     df_expends18 = pd.read_csv('../../data/open_secrets/Expend18/expends18.txt', \n",
    "#                                quotechar='|', \n",
    "#                                sep=',', \n",
    "#                                encoding='ISO-8859-1',\n",
    "#                                header=None,\n",
    "#                                names=['cycle__expends18', 'id__expends18', 'transid__expends18', 'crpfilerid__expends18', \n",
    "#                                       'recipcode__expends18', 'pacshort__expends18', 'crprecipname__expends18', \n",
    "#                                       'expcode__expends18', 'amount__expends18', 'date__expends18', 'city__expends18', 'state__expends18', \n",
    "#                                       'zip__expends18', 'cmteid_ef__expends18', 'candid__expends18', 'type__expends18',\n",
    "#                                       'descrip__expends18', 'pg__expends18', 'elecother__expends18', 'enttype__expends18',\n",
    "#                                       'source__expends18'])\n",
    "#     print(\"Finished.\")\n",
    "    \n",
    "# showdf(df_expends18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d54e36-c0fc-4bf1-a8f7-8dd56951ce53",
   "metadata": {},
   "source": [
    "### Lobby data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb0c02-dec9-405f-9ddc-adecb6560c6d",
   "metadata": {},
   "source": [
    "#### lob_agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa3c13-552d-4211-a2a1-32f627ec1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition for Lobbying Data: Lobby agencies\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_agency.htm\n",
    "try:\n",
    "    df_lob_agency.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_agency = pd.read_csv('../../data/open_secrets/Lobby/lob_agency.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['uniqid__lob_agency',\n",
    "                                      'agencyid__lob_agency', \n",
    "                                      'agency__lob_agency'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_agency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e5fc4-eb6f-4c16-89d4-951dec406313",
   "metadata": {},
   "source": [
    "#### lob_bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903c354-978e-4d16-8c2d-66e301bfafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition for Lobbying Data: Lobby bills\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_bills.htm\n",
    "try:\n",
    "    df_lob_bills.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_bills = pd.read_csv('../../data/open_secrets/Lobby/lob_bills.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['b_id__lob_bills',\n",
    "                                      'si_id__lob_bills', \n",
    "                                      'congno__lob_bills', \n",
    "                                      'bill_name__lob_bills'])\n",
    "    df_lob_bills['bill_name__lob_bills'] = df_lob_bills['bill_name__lob_bills'].apply(lambda x: x[:-2])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_bills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c12ec6-04dc-4bd2-8e0f-7a401fa46f78",
   "metadata": {},
   "source": [
    "#### lob_indus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d56d4-f406-4f3a-96d5-692cbc74e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition for Lobbying Data: Lobby industries\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_indus.htm\n",
    "try:\n",
    "    df_lob_indus.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_indus = pd.read_csv('../../data/open_secrets/Lobby/lob_indus.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['client__lob_indus',\n",
    "                                      'sub__lob_indus', \n",
    "                                      'total__lob_indus', \n",
    "                                      'year__lob_indus', \n",
    "                                      'catcode__lob_indus'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_indus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141dde2-b956-40c0-a16d-fbd04a3b94a4",
   "metadata": {},
   "source": [
    "#### lob_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79ceaa-f866-4d6d-a042-9eb1271f7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition for Lobbying Data: Lobby issues\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_issues.htm\n",
    "try:\n",
    "    df_lob_issue.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_issue = pd.read_csv('../../data/open_secrets/Lobby/lob_issue.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['si_id__lob_issue',\n",
    "                                      'uniqid__lob_issue', \n",
    "                                      'issueid__lob_issue', \n",
    "                                      'issue__lob_issue', \n",
    "                                      'specificissue__lob_issue', \n",
    "                                      'year__lob_issue'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c45b2-9675-4768-94a0-4251f910562e",
   "metadata": {},
   "source": [
    "#### lob_issue_no_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd2670-7101-43cc-829f-67886158a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition for Lobbying Data: Lobby issues (no specific issue)\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_issues.htm\n",
    "try:\n",
    "    df_lob_issue_no_specific.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_issue_no_specific = pd.read_csv('../../data/open_secrets/Lobby/lob_issue_NoSpecficIssue.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['si_id__lob_issue_NoSpecficIssue', 'uniqid__lob_issue_NoSpecficIssue', \n",
    "                                      'issueid__lob_issue_NoSpecficIssue', 'issue__lob_issue_NoSpecficIssue', \n",
    "                                      'year__lob_issue_NoSpecficIssue'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_issue_no_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753c0a1-5461-4127-92dc-1a8805a1b99c",
   "metadata": {},
   "source": [
    "#### lob_lobbying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eda8f1-2d5f-4e71-8433-8644be26a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definitions for Lobbying Data: Lobbying\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_lobbying.htm\n",
    "try:\n",
    "    df_lob_lobbying.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_lobbying = pd.read_csv('../../data/open_secrets/Lobby/lob_lobbying.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['uniqid__lob_lobbying','registrant_raw__lob_lobbying','registrant__lob_lobbying','isfirm__lob_lobbying','client_raw__lob_lobbying','client__lob_lobbying','ultorg__lob_lobbying','amount__lob_lobbying',\n",
    "                                      'catcode__lob_lobbying','source__lob_lobbying','self__lob_lobbying','includensfs__lob_lobbying','use__lob_lobbying',\n",
    "                                      'ind__lob_lobbying', 'year__lob_lobbying', 'type__lob_lobbying', 'typelong__lob_lobbying', 'affiliate__lob_lobbying'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_lobbying)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3874e-38be-47ab-bdfb-2d93187591b9",
   "metadata": {},
   "source": [
    "#### lob_lobbyist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb3697-bb91-45f9-9995-b67200f4f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definition for Lobbyists\n",
    "# https://www.opensecrets.org/resources/datadictionary/Data%20Dictionary%20lob_lobbyists.htm\n",
    "try:\n",
    "    df_lob_lobbyist.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_lobbyist = pd.read_csv('../../data/open_secrets/Lobby/lob_lobbyist.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['uniqid__lob_lobbyist', 'lobbyist_lastname_std__lob_lobbyist', 'lobbyist_firstname_std__lob_lobbyist', 'lobbyist_lastname_raw__lob_lobbyist', \n",
    "                                      'lobbyist_firstname_raw__lob_lobbyist', 'lobbyist_id__lob_lobbyist', 'year__lob_lobbyist', 'officialposition__lob_lobbyist', 'cid__lob_lobbyist', 'formercongmem__lob_lobbyist'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_lobbyist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728e719-18e9-443a-9411-37030071eed2",
   "metadata": {},
   "source": [
    "#### lob_rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41adcd4-16c9-40a7-a129-003b8bb20584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSecrets Data Definitions for Lobbying Data: Report types\n",
    "# No documentation provided on OpenSecrets.com\n",
    "try:\n",
    "    df_lob_rpt.head()\n",
    "except NameError:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_rpt = pd.read_csv('../../data/open_secrets/Lobby/lob_rpt.txt', \n",
    "                               quotechar='|', \n",
    "                               sep=',', \n",
    "                               encoding='ISO-8859-1',\n",
    "                               header=None,\n",
    "                               names=['typelong__lob_rpt', 'typeshort__lob_rpt'])\n",
    "    print(\"Finished.\")\n",
    "\n",
    "showdf(df_lob_rpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50242f1-ae31-424f-840c-6bc3909ce73b",
   "metadata": {},
   "source": [
    "### IDs and categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d0a84-4800-4933-a3d5-53d86134bbd1",
   "metadata": {},
   "source": [
    "#### CRP_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64023e77-2070-4434-91e0-76095ad6cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_if_needed('xlrd')\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c143fb-27fc-4fb7-9a40-85b811d8ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate ids\n",
    "# This dataset is very different, so load it independently.\n",
    "columns_crp_ids = ['blank_excel_column__crp_ids', 'cid__crp_ids', 'crpname__crp_ids', 'party__crp_ids', 'distidrunfor__crp_ids', 'feccandid__crp_ids'] # Blank excel column is necessary.\n",
    "columns_crp_ids = dict(enumerate(columns_crp_ids))\n",
    "df_crp_ids = pd.read_excel('../../data/open_secrets/CRP_IDs.xls', header=None, skiprows=15)\n",
    "df_crp_ids = df_crp_ids.drop(df_crp_ids.columns[0], axis=1)\n",
    "df_crp_ids = df_crp_ids.rename(columns=columns_crp_ids)\n",
    "showdf(df_crp_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3585e1-ad2e-4aa9-b93a-2590564bfd97",
   "metadata": {},
   "source": [
    "#### CRP_Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa276e-f8c5-48d7-ae32-fee63955346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "crp_filepath = '../../data/open_secrets/CRP_Categories.txt'\n",
    "with open(crp_filepath, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "header_line_index = next(i for i, line in enumerate(lines) if line.startswith('Catcode'))\n",
    "table_data = ''.join(lines[header_line_index:])\n",
    "df_crp_cats = pd.read_csv(StringIO(table_data), sep='\\t')\n",
    "df_crp_cats.columns = df_crp_cats.columns.str.lower().str.replace(' ', '_')\n",
    "df_crp_cats.columns = [col + '__crp_cats' for col in df_crp_cats.columns]\n",
    "\n",
    "showdf(df_crp_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8433f3a-b64b-478f-80fb-5b44a7fe4be9",
   "metadata": {},
   "source": [
    "## Ways and Means Network\n",
    "*Toy network & full network of member campaign contributions from the 2018 election, resulting in the 116th Congress*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f59b2-9eba-41fd-b9be-7b456bf5567c",
   "metadata": {},
   "source": [
    "#### Dataframe of committee members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe6dad-3d2c-4a33-8ed4-52a0ea05e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_dem_members = []\n",
    "with open('../../data/wm_members_dem.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        wm_dem_members.append(row)\n",
    "\n",
    "df_wm_dem_members = df_cands18[df_cands18['firstlast__cands18'].isin(wm_dem_members[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c923449-fe58-4b3d-b403-906fa035908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_rep_members = []\n",
    "with open('../../data/wm_members_rep.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        wm_rep_members.append(row)\n",
    "\n",
    "df_wm_rep_members = df_cands18[df_cands18['firstlast__cands18'].isin(wm_rep_members[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4dc8f0-e24f-47b2-884e-1e7f514fd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm_members = pd.concat([df_wm_dem_members, df_wm_rep_members])\n",
    "df_wm_members = df_wm_members.drop_duplicates(subset='firstlast__cands18', keep='first') # Some are duplicates, safe to remove.\n",
    "showdf(df_wm_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e289b-de67-4ad5-822c-876f7441cc1b",
   "metadata": {},
   "source": [
    "#### Pre-defined members for toy network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35e484-7752-4c81-a482-86ffce0cc175",
   "metadata": {},
   "source": [
    "Richard E Neal (R), chairman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8b3be-4626-4b13-8ff9-915ea10158a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_cid_1 = 'N00000153'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf908a1-6a1d-440f-bdbb-4d27671bfad2",
   "metadata": {},
   "source": [
    "Kevin Brady (D), ranking member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef24d3a6-7e33-4b76-bb95-662f85645204",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_cid_2 = 'N00005883'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932d02a-7a80-48cd-86fc-ed4e253c6cb5",
   "metadata": {},
   "source": [
    "Lloyd Doggett (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4295444-315f-47e8-825d-e790303f0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_cid_3 = 'N00006023'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c6568-392f-4035-b227-b074d7e972ba",
   "metadata": {},
   "source": [
    "Devin Nunes (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1540e6-a21d-4fdb-a5de-698ebbe639ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_cid_4 = 'N00007248'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107250d3-9248-4708-b36b-cf2514a2be58",
   "metadata": {},
   "source": [
    "John B Larson (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5aded-2c18-4268-b6bd-aaa9b54dc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_cid_5 = 'N00000575'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bbcc7-9b3d-48f3-b5b5-a2e9c07a2d0b",
   "metadata": {},
   "source": [
    "Vernon Buchanan (R) \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8eb7f-e426-44b9-b1b3-db8cbbe0af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_cid_6 = 'N00027626'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af644353-594b-4a3b-adfc-4934a2b28c50",
   "metadata": {},
   "source": [
    "#### Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd162b8-e07c-43f9-b514-fa1d13a67d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting to the two members above.\n",
    "df_toy_network = df_wm_members[\n",
    "    (df_wm_members['cid__cands18'] == member_cid_1) | \\\n",
    "    (df_wm_members['cid__cands18'] == member_cid_2) | \\\n",
    "    (df_wm_members['cid__cands18'] == member_cid_3) | \\\n",
    "    (df_wm_members['cid__cands18'] == member_cid_4) | \\\n",
    "    (df_wm_members['cid__cands18'] == member_cid_5) | \\\n",
    "    (df_wm_members['cid__cands18'] == member_cid_6)\n",
    "]\n",
    "\n",
    "# No limits for the full network.\n",
    "df_full_network = df_wm_members.copy()\n",
    "\n",
    "showdf(df_toy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fc81f-c616-42cd-844b-1f6076777054",
   "metadata": {},
   "source": [
    "#### Candidate pacs\n",
    "Extract candidate pacs/cmtes from the others and augment column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5fc5b-09c9-4524-9657-0cfede1c1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cand_cmtes18 = df_cmtes18[df_cmtes18['recipid__cmtes18'].str.startswith('N')] # Only candidate committees.\n",
    "df_cand_cmtes18.columns = df_cand_cmtes18.columns.str.replace(r\"(cmtes18)\", r\"cand_\\1\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f68a68-6b01-4864-949a-10b25cb2c8e2",
   "metadata": {},
   "source": [
    "#### Non-candidate pacs\n",
    "While we're at it, extract all the non-partisan/candidate pacs and augment column names for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd74a35-8da5-4b7c-a8fc-96ad24c0a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noncand_cmtes18 = df_cmtes18[df_cmtes18['party__cmtes18'].isna()] # Excludes party, joint fundraising, leadership, or candidate committees.\n",
    "df_noncand_cmtes18['sensitive__cmtes18'] = df_noncand_cmtes18['sensitive__cmtes18'].apply(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "df_noncand_cmtes18.columns = df_noncand_cmtes18.columns.str.replace(r\"(cmtes18)\", r\"noncand_\\1\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696b39f-2d23-444d-a8b3-26076ac5911a",
   "metadata": {},
   "source": [
    "#### Join candidates and candidate pacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45d5f6-2b9e-4e96-957b-8f8086a07f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy_network = pd.merge(df_toy_network, df_cand_cmtes18, left_on='cid__cands18', right_on='recipid__cand_cmtes18', how='inner')\n",
    "df_full_network = pd.merge(df_full_network, df_cand_cmtes18, left_on='cid__cands18', right_on='recipid__cand_cmtes18', how='inner')\n",
    "showdf(df_toy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f990d-6cb8-455d-9e81-9ed0f35ebc44",
   "metadata": {},
   "source": [
    "#### Join inflows for each candidate pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69800259-8080-4a86-9c83-6a71443d23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflow_pacs18 = df_pacs18[df_pacs18['amount__pacs18'] > 500] # Exclude outflows and small contributions.\n",
    "df_toy_network = pd.merge(df_toy_network, df_inflow_pacs18, left_on='cid__cands18', right_on='cid__pacs18', how='inner')\n",
    "df_full_network = pd.merge(df_full_network, df_inflow_pacs18, left_on='cid__cands18', right_on='cid__pacs18', how='inner')\n",
    "showdf(df_toy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfd08f-9e87-49ea-814e-074f8b95003e",
   "metadata": {},
   "source": [
    "#### Join sources of inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e099db7-00f9-4248-bac5-89988d17eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy_network = pd.merge(df_toy_network, df_noncand_cmtes18, left_on='pacid__pacs18', right_on='cmteid__noncand_cmtes18', how='inner')\n",
    "df_full_network = pd.merge(df_full_network, df_noncand_cmtes18, left_on='pacid__pacs18', right_on='cmteid__noncand_cmtes18', how='inner')\n",
    "showdf(df_toy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea4b0e-11f2-4e06-be9e-a607aa7aa676",
   "metadata": {},
   "source": [
    "#### Join source's industry category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1830efb-d89b-4e1f-971e-edae19dc212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy_network = pd.merge(df_toy_network, df_crp_cats, left_on='primcode__noncand_cmtes18', right_on='catcode__crp_cats', how='inner')\n",
    "df_full_network = pd.merge(df_full_network, df_crp_cats, left_on='primcode__noncand_cmtes18', right_on='catcode__crp_cats', how='inner')\n",
    "showdf(df_toy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f6321-e998-446f-b0a5-8dd09a9b9a32",
   "metadata": {},
   "source": [
    "#### Join industry details of category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31930a8-06af-4c56-8150-ca4ef582c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lob_indus_2018 = df_lob_indus[df_lob_indus['year__lob_indus'] == 2018]\n",
    "df_toy_network = pd.merge(df_toy_network, df_lob_indus_2018, left_on='ultorg__noncand_cmtes18', right_on='client__lob_indus', how='left')\n",
    "df_full_network = pd.merge(df_full_network, df_lob_indus_2018, left_on='ultorg__noncand_cmtes18', right_on='client__lob_indus', how='left')\n",
    "showdf(df_toy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273c633-2838-4482-a247-6f92fa6cd165",
   "metadata": {},
   "source": [
    "#### Final cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e96320-a933-4cc5-ae78-a0eb6ec8c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['cycle__cands18', 'feccandid__cands18', 'firstlastp__cands18', 'distidrunfor__cands18', 'distidcurr__cands18',\n",
    "                'currcand__cands18', 'cyclecand__cands18', 'recipcode__cands18', 'nopacs__cands18', 'cycle__cand_cmtes18', 'pacshort__cand_cmtes18',\n",
    "                'affiliate__cand_cmtes18', 'recipid__cand_cmtes18', 'recipcode__cand_cmtes18',\n",
    "                'feccandid__cand_cmtes18', 'party__cand_cmtes18', 'primcode__cand_cmtes18', 'source__cand_cmtes18',\n",
    "                'sensitive__cand_cmtes18', 'foreign__cand_cmtes18', 'active__cand_cmtes18', 'cycle__pacs18', 'fecrecno__pacs18',\n",
    "                'pacid__pacs18', 'cid__pacs18', 'realcode__pacs18', 'type__pacs18', 'di__pacs18',\n",
    "                'feccandid__pacs18', 'cycle__noncand_cmtes18', 'pacshort__noncand_cmtes18', 'affiliate__noncand_cmtes18', 'recipid__noncand_cmtes18', \n",
    "                'feccandid__noncand_cmtes18', 'party__noncand_cmtes18', 'primcode__noncand_cmtes18', \n",
    "                'source__noncand_cmtes18', 'active__noncand_cmtes18', 'catcode__crp_cats', 'catorder__crp_cats', 'year__lob_indus']\n",
    "\n",
    "df_toy_network = df_toy_network.drop(drop_columns, axis=1)\n",
    "df_full_network = df_full_network.drop(drop_columns, axis=1)\n",
    "\n",
    "showdf(df_toy_network)\n",
    "to_csv(df_toy_network)\n",
    "to_csv(df_full_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff85756-e8da-4b2d-9482-3d3a3f7be48a",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "Create a dataframe connected a table of personal candidate info and their candidate pac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ebf9d-f00c-4607-82bf-bdaf1d631f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph_network = df_full_network.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087377e-4e03-4f16-ab09-440ecec0202d",
   "metadata": {},
   "source": [
    "#### Fields to be graphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e02a62-8688-48ff-a0ac-3c1a603de2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target, source, weight, attribute\n",
    "df_candpacs_to_pactrans = df_graph_network[['ultorg__cand_cmtes18', 'ultorg__noncand_cmtes18', 'amount__pacs18', 'party__cands18', 'recipcode__noncand_cmtes18', 'sector__crp_cats']]\n",
    "showdf(df_candpacs_to_pactrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22acf2fc-f85a-40f8-b119-17e4e3b5974e",
   "metadata": {},
   "source": [
    "#### Join same-party candidate pacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27ff98-1317-4b45-b3a8-3059e110c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dem_candpacs = df_candpacs_to_pactrans[df_candpacs_to_pactrans['party__cands18'] == 'D'][['ultorg__cand_cmtes18']].drop_duplicates()\n",
    "df_dem_candpacs = df_candpacs_to_pactrans[df_candpacs_to_pactrans['party__cands18'] == 'D'][['ultorg__cand_cmtes18']].drop_duplicates()\n",
    "df_dem_candpacs_cross = pd.merge(df_dem_candpacs, df_dem_candpacs, how='cross')\n",
    "df_dem_candpacs_cross = df_dem_candpacs_cross[df_dem_candpacs_cross['ultorg__cand_cmtes18_x'] != df_dem_candpacs_cross['ultorg__cand_cmtes18_y']].rename(columns={'ultorg__cand_cmtes18_x': 'ultorg_x__cand_cmtes18', 'ultorg__cand_cmtes18_y': 'ultorg_y__cand_cmtes18'})\n",
    "showdf(df_dem_candpacs_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d7cba-c1e4-4f27-8a1b-9febb07cadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_candpacs = df_candpacs_to_pactrans[df_candpacs_to_pactrans['party__cands18'] == 'R'][['ultorg__cand_cmtes18']].drop_duplicates()\n",
    "df_rep_candpacs = df_candpacs_to_pactrans[df_candpacs_to_pactrans['party__cands18'] == 'R'][['ultorg__cand_cmtes18']].drop_duplicates()\n",
    "df_rep_candpacs_cross = pd.merge(df_rep_candpacs, df_rep_candpacs, how='cross')\n",
    "df_rep_candpacs_cross = df_rep_candpacs_cross[df_rep_candpacs_cross['ultorg__cand_cmtes18_x'] != df_rep_candpacs_cross['ultorg__cand_cmtes18_y']].rename(columns={'ultorg__cand_cmtes18_x': 'ultorg_x__cand_cmtes18', 'ultorg__cand_cmtes18_y': 'ultorg_y__cand_cmtes18'})\n",
    "showdf(df_rep_candpacs_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9565ac2-755e-4e7e-9e7b-82ae2a558392",
   "metadata": {},
   "source": [
    "### Candidates to Bills\n",
    "Use data from api.congress.gov to lookup bills from a specific session of Congress, and join associated candidate [co]sponsoring information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc16853-47b8-4acb-8ec7-c0d22aeb4487",
   "metadata": {},
   "source": [
    "#### Get list of member numbers\n",
    "The list is different than Cands22 in that it maps a different ID to candidates, which we need to lookup bills that they've [co]sponsored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a53a8-12be-43f7-aa11-63b510f77439",
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_member_limit = '250'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37bc86-c5bf-4bb7-8099-ffd7cf9534fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/congress_api/congress_members116.json'\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    print(f\"Data source at {filepath} not found, generating from Congress.gov's remote API..\")\n",
    "\n",
    "    api_endpoint = f\"member/congress/{CONGRESS_NUM}\"\n",
    "    api_params = {\n",
    "        \"limit\": cong_member_limit,\n",
    "        \"api_key\": CONGRESS_API_KEY,\n",
    "        \"offset\": '0',\n",
    "    }\n",
    "    \n",
    "    # Get number of pages (offset) to loop through, where\n",
    "    # each page has up to 250 rows.\n",
    "    api_page_params = api_params.copy()\n",
    "    api_page_params['limit'] = '1'\n",
    "    page_response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_page_params)\n",
    "    page_count = (page_response.json()['pagination']['count']) // int(cong_member_limit) + 1 # add 1 b/c we are rounding down\n",
    "\n",
    "    members = []\n",
    "    offset = 0\n",
    "    page_num = 0\n",
    "    for i in list(range(page_count)):\n",
    "        page_num += 1\n",
    "\n",
    "        print(f\"Reading page {page_num}...\") \n",
    "  \n",
    "        api_params['offset'] = offset\n",
    "        response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_params)\n",
    "        members.append(response.json()['members'])\n",
    "        offset += int(cong_member_limit)\n",
    "\n",
    "    print(f\"Formatting data...\")\n",
    "\n",
    "    # Convert lists of dicts into one dict.\n",
    "    members_dict = [item for sublist in members for item in sublist]\n",
    "\n",
    "    # Save as json.    \n",
    "    with open(filepath, 'w') as json_file:\n",
    "        print(f\"Saving data...\")\n",
    "        json.dump(members_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Data saved at {filepath}\")\n",
    "\n",
    "# Create and process df.\n",
    "print(f\"Loading dataframe...\")\n",
    "\n",
    "df_cong_members = pd.read_json(filepath)\n",
    "\n",
    "print(f\"Finished.\")\n",
    "\n",
    "showdf(df_cong_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc39dc5-280c-4e9e-b4c3-17c131f55fb3",
   "metadata": {},
   "source": [
    "#### Extract WM members"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f4766-77a3-4d84-8bb8-613e1c66fd52",
   "metadata": {},
   "source": [
    "**Match Congress.gov records to CampaignFin18 records**\n",
    "<br>Because the data is real shitty, we'll need to match on last name, state abbreviation, and party abbreviation, which should be plenty enough accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcc54f-bd9d-49eb-8084-69e725392dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map states to abbreviations.\n",
    "state_abbrev = pd.read_csv('../../data/state_abbrev.csv')\n",
    "state_abbrev = state_abbrev.rename(columns={'State': 'state', 'Abbreviation': 'state_abbrev'})\n",
    "showdf(state_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466a557-55fe-4fb4-9a24-a9aad40b079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accents from names.\n",
    "import unicodedata\n",
    "def remove_accents(input_str):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', input_str)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Note: df_cong_members is created a few cells up.\n",
    "# Below, the three new fields should only be set once to prevent fudging up the df.\n",
    "if 'last_name' not in df_cong_members.columns:\n",
    "    df_cong_members = pd.merge(df_cong_members, state_abbrev, on='state', how='inner')\n",
    "    df_cong_members['last_name'] = df_cong_members['name'].apply(lambda x: x.split(\",\")[0])\n",
    "    df_cong_members['last_name'] = df_cong_members['last_name'].apply(lambda x: remove_accents(x)) # remove accents\n",
    "    df_cong_members['party_abbrev'] = df_cong_members['partyName'].apply(lambda x: x[:1])\n",
    "\n",
    "showdf(df_cong_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a22f0e-996a-4ad1-a7ac-9c48b90a33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm_members = df_wm_members.merge(\n",
    "    df_cong_members[['last_name', 'state_abbrev', 'party_abbrev', 'bioguideId']],\n",
    "    on=['last_name', 'state_abbrev', 'party_abbrev'],\n",
    "    how='left'\n",
    ")\n",
    "showdf(df_wm_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7b60e-e494-4b35-a81f-483c993de51f",
   "metadata": {},
   "source": [
    "#### Find bills [co]sponsored by WM members"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303bd79e-8ae0-4531-b264-33fa8d243428",
   "metadata": {},
   "source": [
    "**Make into one function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d06b45-d9e4-4461-8cca-a631c1251420",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/congress_api/congress_sponsors116.json'\n",
    "limit = 250\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    print(f\"Data source at {filepath} not found, generating from Congress.gov's remote API..\")\n",
    "\n",
    "    # Get [co]sponsored bills for each member.\n",
    "    rows = []\n",
    "    for index, row in df_wm_members.iterrows():\n",
    "        print(f\"Processing member {index + 1} of {len(df_wm_members)}...\")\n",
    "        \n",
    "        bioguide_id = row['bioguideId']\n",
    "        api_endpoint = f\"member/{bioguide_id}/sponsored-legislation\"\n",
    "        api_params = {\n",
    "            \"limit\": limit,\n",
    "            \"api_key\": CONGRESS_API_KEY,\n",
    "            \"offset\": '0',\n",
    "        }\n",
    "        \n",
    "        # Get number of pages.\n",
    "        api_page_params = api_params.copy()\n",
    "        api_page_params['limit'] = '1'\n",
    "        page_response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_page_params)\n",
    "        page_count = (page_response.json()['pagination']['count']) // int(limit) + 1 # add 1 b/c we are rounding down\n",
    "    \n",
    "        offset = 0\n",
    "        page_num = 0\n",
    "        for i in list(range(page_count)):\n",
    "            page_num += 1\n",
    "    \n",
    "            print(f\"Reading page {page_num}...\") \n",
    "      \n",
    "            api_params['offset'] = offset\n",
    "            response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_params)\n",
    "            response_json = response.json()\n",
    "            \n",
    "            # Add metadata from the member to each item in the 'sponsoredLegislation'\n",
    "            for item in response_json.get('sponsoredLegislation', []):\n",
    "                item['member_cid'] = row['cid__cands18']\n",
    "                item['member_bioguideId'] = row['bioguideId']\n",
    "    \n",
    "            # Append the items to rows\n",
    "            rows.append(response_json.get('sponsoredLegislation', []))\n",
    "            \n",
    "            offset += int(limit)\n",
    "\n",
    "    print(f\"Formatting data...\")\n",
    "\n",
    "    # Convert lists of dicts into one dict.\n",
    "    rows_dict = [item for sublist in rows for item in sublist]\n",
    "\n",
    "    # Save as json.    \n",
    "    with open(filepath, 'w') as json_file:\n",
    "        print(f\"Saving data...\")\n",
    "        json.dump(rows_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Data saved at {filepath}\")\n",
    "\n",
    "# Create and process df.\n",
    "print(f\"Loading dataframe...\")\n",
    "\n",
    "df_wm_sponsors = pd.read_json(filepath)\n",
    "\n",
    "print(f\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2eaee6-9790-43c9-bd50-72ec494aec92",
   "metadata": {},
   "source": [
    "**CURRENTLY THIS CONTAINS THE SAME OUTPUT AS ABOVE!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b4489-be4a-4b3f-9865-61ec3296fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/congress_api/congress_cosponsors116.json'\n",
    "limit = 250\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    print(f\"Data source at {filepath} not found, generating from Congress.gov's remote API..\")\n",
    "\n",
    "    # Get [co]sponsored bills for each member.\n",
    "    rows = []\n",
    "    for index, row in df_wm_members.iterrows():\n",
    "        print(f\"Processing member {index + 1} of {len(df_wm_members)}...\")\n",
    "        \n",
    "        bioguide_id = row['bioguideId']\n",
    "        api_endpoint = f\"member/{bioguide_id}/cosponsored-legislation\"\n",
    "        api_params = {\n",
    "            \"limit\": limit,\n",
    "            \"api_key\": CONGRESS_API_KEY,\n",
    "            \"offset\": '0',\n",
    "        }\n",
    "        \n",
    "        # Get number of pages.\n",
    "        api_page_params = api_params.copy()\n",
    "        api_page_params['limit'] = '1'\n",
    "        page_response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_page_params)\n",
    "        page_count = (page_response.json()['pagination']['count']) // int(limit) + 1 # add 1 b/c we are rounding down\n",
    "    \n",
    "        offset = 0\n",
    "        page_num = 0\n",
    "        for i in list(range(page_count)):\n",
    "            page_num += 1\n",
    "    \n",
    "            print(f\"Reading page {page_num}...\") \n",
    "      \n",
    "            api_params['offset'] = offset\n",
    "            response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_params)\n",
    "            response_json = response.json()\n",
    "            \n",
    "            # Add metadata from the member to each item in the 'sponsoredLegislation'\n",
    "            for item in response_json.get('cosponsoredLegislation', []):\n",
    "                item['member_cid'] = row['cid__cands18']\n",
    "                item['member_bioguideId'] = row['bioguideId']\n",
    "    \n",
    "            # Append the items to rows\n",
    "            rows.append(response_json.get('cosponsoredLegislation', []))\n",
    "            \n",
    "            offset += int(limit)\n",
    "\n",
    "    print(f\"Formatting data...\")\n",
    "\n",
    "    # Convert lists of dicts into one dict.\n",
    "    rows_dict = [item for sublist in rows for item in sublist]\n",
    "\n",
    "    # Save as json.    \n",
    "    with open(filepath, 'w') as json_file:\n",
    "        print(f\"Saving data...\")\n",
    "        json.dump(rows_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Data saved at {filepath}\")\n",
    "\n",
    "# Create and process df.\n",
    "print(f\"Loading dataframe...\")\n",
    "\n",
    "df_wm_cosponsors = pd.read_json(filepath)\n",
    "\n",
    "print(f\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394eec4-b2f1-45e5-8222-24cbd70fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 116th\n",
    "df_wm_sponsors116 = df_wm_sponsors[df_wm_sponsors['congress'] == 116].reset_index(drop=True)\n",
    "df_wm_cosponsors116 = df_wm_sponsors[df_wm_sponsors['congress'] == 116].reset_index(drop=True)\n",
    "\n",
    "# Some bill numbers are nan.\n",
    "df_wm_sponsors116 = df_wm_sponsors116.dropna(subset=['number'])\n",
    "df_wm_cosponsors116 = df_wm_cosponsors116.dropna(subset=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97bf57e-870c-48e3-8f1a-c1334a760fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wm_sponsors116_copy = df_wm_sponsors116.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d0d36-0b06-43d8-b2ee-8f8fc8ceac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showdf(df_wm_sponsors116_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5e42f-ab22-4b67-bcd6-1ce3708c0a27",
   "metadata": {},
   "source": [
    "#### Find details of each [co]sponsored bill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbff3e7-d248-4e60-a4f3-5dacf26f087d",
   "metadata": {},
   "source": [
    "**Make into one function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be7857-8251-444e-a7a1-87fdcf5cb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_chamber = 'hr'\n",
    "filepath = '../../data/congress_api/congress_wm_spons_bills116.json'\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    print(f\"Data source at {filepath} not found, generating from Congress.gov's remote API..\")\n",
    "\n",
    "    # Get [co]sponsored bills for each member.\n",
    "    rows = []\n",
    "    for index, row in df_wm_sponsors116.iterrows():\n",
    "        if i % (len(df_wm_sponsors116) // 100) == 0:\n",
    "            print(f\"Processing bill {index + 1} of {len(df_wm_sponsors116)}...\")\n",
    "\n",
    "        bill_num = int(row['number'])\n",
    "        api_endpoint = f\"bill/{CONGRESS_NUM}/{congress_chamber}/{bill_num}\"\n",
    "        api_params = {\n",
    "            \"api_key\": CONGRESS_API_KEY,\n",
    "        }\n",
    "        response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_params)\n",
    "        response_json = response.json()\n",
    "        rows.append(response_json['bill'])\n",
    "\n",
    "    print(f\"Formatting data...\")\n",
    "\n",
    "    # Convert lists of dicts into one dict.\n",
    "    # But if rows is already flat, skip flattening into one dict.\n",
    "    if any(isinstance(item, list) for item in rows):\n",
    "        rows_dict = [item for sublist in rows for item in sublist]\n",
    "    else:\n",
    "        rows_dict = rows\n",
    "\n",
    "    # Save as json.    \n",
    "    with open(filepath, 'w') as json_file:\n",
    "        print(f\"Saving data...\")\n",
    "        json.dump(rows_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Data saved at {filepath}\")\n",
    "\n",
    "# Create and process df.\n",
    "print(f\"Loading dataframe...\")\n",
    "\n",
    "df_wm_spons_bills = pd.read_json(filepath)\n",
    "\n",
    "print(f\"Finished.\")\n",
    "\n",
    "showdf(df_wm_spons_bills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022966d3-8a78-48c6-9372-03ef298269b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_chamber = 'hr'\n",
    "filepath = '../../data/congress_api/congress_wm_cospons_bills116.json'\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    print(f\"Data source at {filepath} not found, generating from Congress.gov's remote API..\")\n",
    "\n",
    "    # Get [co]sponsored bills for each member.\n",
    "    rows = []\n",
    "    for index, row in df_wm_cosponsors116.iterrows():\n",
    "        if i % (len(df_wm_cosponsors116) // 100) == 0:\n",
    "            print(f\"Processing bill {index + 1} of {len(df_wm_cosponsors116)}...\")\n",
    "\n",
    "        bill_num = int(row['number'])\n",
    "        api_endpoint = f\"bill/{CONGRESS_NUM}/{congress_chamber}/{bill_num}\"\n",
    "        api_params = {\n",
    "            \"api_key\": CONGRESS_API_KEY,\n",
    "        }\n",
    "        response = requests.get(CONGRESS_API_URL + api_endpoint, params=api_params)\n",
    "        response_json = response.json()\n",
    "        rows.append(response_json['bill'])\n",
    "\n",
    "    print(f\"Formatting data...\")\n",
    "\n",
    "    # Convert lists of dicts into one dict.\n",
    "    # But if rows is already flat, skip flattening into one dict.\n",
    "    if any(isinstance(item, list) for item in rows):\n",
    "        rows_dict = [item for sublist in rows for item in sublist]\n",
    "    else:\n",
    "        rows_dict = rows\n",
    "\n",
    "    # Save as json.    \n",
    "    with open(filepath, 'w') as json_file:\n",
    "        print(f\"Saving data...\")\n",
    "        json.dump(rows_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Data saved at {filepath}\")\n",
    "\n",
    "# Create and process df.\n",
    "print(f\"Loading dataframe...\")\n",
    "\n",
    "df_wm_cospons_bills = pd.read_json(filepath)\n",
    "\n",
    "print(f\"Finished.\")\n",
    "\n",
    "showdf(df_wm_cospons_bills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f7525-3c9c-4786-b7b8-f4cf143c2f68",
   "metadata": {},
   "source": [
    "#### Join [co]sponsors to bill details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9664f-2b53-435d-8f47-be0652672d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'm trying to extract the \"name\" from \"policyArea\"\n",
    "# df_wm_spons_bills.iloc[1]['policyArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb45ffa-628e-43ee-ab77-1c28cdd8de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm_spons_bills['bioguidID'] = df_wm_spons_bills['sponsors'].apply(lambda x: x[0]['bioguideId'])\n",
    "\n",
    "# # TRYING TO EXTRACT POLICY AREA!\n",
    "# df_wm_spons_bills['policyArea'] = df_wm_spons_bills['policyArea'].apply(lambda x: str(x))\n",
    "# df_wm_spons_bills['policyArea_clean'] = df_wm_spons_bills['policyArea'].apply(lambda x: json.loads(x)['name'] if pd.notnull(x) else None)\n",
    "\n",
    "df_wm_spons_bills = df_wm_spons_bills[['congress', 'introducedDate', 'number', 'title', 'bioguidID']]\n",
    "showdf(df_wm_spons_bills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f24878-ff0f-4e59-b508-e04ace99f182",
   "metadata": {},
   "source": [
    "#### Join candidates to [co]sponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a842412-976c-4d84-a227-6930bc4f8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm_candspons_bills = pd.merge(df_wm_spons_bills, df_wm_members, left_on='bioguidID', right_on='bioguideId', how='inner')\n",
    "df_wm_candspons_bills = pd.merge(df_wm_candspons_bills, df_cmtes18, left_on='cid__cands18', right_on='recipid__cmtes18', how='inner')\n",
    "showdf(df_wm_candspons_bills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562dcf0-4089-4f5b-a4a2-34e577f7bd64",
   "metadata": {},
   "source": [
    "### Bills to Issues, Policy Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec27df-70d6-4b1c-ae06-d84c62e96460",
   "metadata": {},
   "source": [
    "#### Bills from 116th Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b29d46-4fcb-4f1f-9f53-69dd6df455f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_lob_bills116.head()\n",
    "except:\n",
    "    print(\"Creating dataframe...\")\n",
    "    df_lob_bills116 = df_lob_bills[(df_lob_bills['congno__lob_bills'].notna()) & (df_lob_bills['b_id__lob_bills'].str.startswith('hr'))]\n",
    "    df_lob_bills116['congno__lob_bills'] = df_lob_bills116['congno__lob_bills'].astype(int)\n",
    "    df_lob_bills116 = df_lob_bills116[df_lob_bills116['congno__lob_bills'] == CONGRESS_NUM]\n",
    "    df_lob_bills116 = df_lob_bills116[~ df_lob_bills116['b_id__lob_bills'].str.contains('hres')]\n",
    "    # Extract bill number text between \"hr\" and \"-116\".\n",
    "    df_lob_bills116['b_id_num__lob_bills'] = df_lob_bills116['b_id__lob_bills'].apply(lambda x: re.search(r'[a-zA-Z]+(\\d+)-', x).group(1))\n",
    "    df_lob_bills116 = df_lob_bills116.sort_values(by='b_id_num__lob_bills', ascending=True)\n",
    "    print(\"Finished\")\n",
    "\n",
    "showdf(df_lob_bills116)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e672d46-e268-4c14-a64e-cc279038bb6d",
   "metadata": {},
   "source": [
    "#### Lob issues\n",
    "filtered Jan-3-2019 to Jan-3-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7f0b1-5199-44e8-8062-7b1478e40850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lob_issue116 = df_lob_issue.copy()\n",
    "df_lob_issue116['year__lob_issue'] = df_lob_issue116['year__lob_issue'].astype(int)\n",
    "df_lob_issue116 = df_lob_issue[(df_lob_issue116['year__lob_issue'] == 2019) | (df_lob_issue116['year__lob_issue'] == 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f36f9-acbc-407c-bba0-04359ff41a74",
   "metadata": {},
   "source": [
    "#### Join bills with issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abaae6-9727-47c2-b075-5ac218398d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lob_bills_issues116 = pd.merge(df_lob_bills116, df_lob_issue116, left_on='si_id__lob_bills', right_on='si_id__lob_issue', how='inner')\n",
    "showdf(df_lob_bills_issues116)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dfd934-3603-44c6-bf95-dbee799b08fb",
   "metadata": {},
   "source": [
    "## Ways and Means Visualization\n",
    "Intention is to create a very large and changeable network where specified notes/classes can be toggled in various ways to create different expressions of various network concepts. This should really be a class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2c12a-7903-4971-8a16-aed9515bc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP GRAPH\n",
    "# ============================================================\n",
    "\n",
    "# Add transactional cand_pac-noncand_pac edges.\n",
    "G = nx.from_pandas_edgelist(df_candpacs_to_pactrans, source='ultorg__noncand_cmtes18', target='ultorg__cand_cmtes18', \n",
    "                            edge_attr='amount__pacs18', create_using=nx.DiGraph())\n",
    "\n",
    "# USE A DIGRAPH FOR PROGRAMATIC ANALSYIS, BUT NOT FOR VIZ.\n",
    "# G = nx.from_pandas_edgelist(df_candpacs_to_pactrans, source='ultorg__noncand_cmtes18', target='ultorg__cand_cmtes18', \n",
    "                            # edge_attr='amount__pacs18', create_using=nx.DiGraph())\n",
    "\n",
    "# Add Democrat cand_pac-cand_pac edges.\n",
    "for _, row in df_dem_candpacs_cross.iterrows():\n",
    "    G.add_edge(row['ultorg_x__cand_cmtes18'], row['ultorg_y__cand_cmtes18'], weight=1, attribute='D')\n",
    "\n",
    "# Add Republican cand_pac-cand_pac edges.\n",
    "for _, row in df_rep_candpacs_cross.iterrows():\n",
    "    G.add_edge(row['ultorg_x__cand_cmtes18'], row['ultorg_y__cand_cmtes18'], weight=1, attribute='R')\n",
    "\n",
    "# Add [co]sponsored bills and details.\n",
    "for _, row in df_wm_candspons_bills.iterrows():\n",
    "    G.add_edge(row['number'], row['cmteid__cmtes18'], weight=1, attribute=row['title'])\n",
    "\n",
    "# # Add issues to bills.\n",
    "# for _, row in df_lob_bills_issues116.iterrows():\n",
    "#     G.add_edge(row['si_id__lob_issue'], row['b_id_num__lob_bills'], weight=1, attribute=row['issue__lob_issue'])\n",
    "\n",
    "# Edge weights ~ dollar amounts.\n",
    "edge_weights = []\n",
    "for edge in G.edges(data=True):\n",
    "    source, target, attributes = edge\n",
    "    if 'amount__pacs18' in attributes:\n",
    "        edge_weights.append(attributes['amount__pacs18'])\n",
    "\n",
    "# Spread weight range.\n",
    "min_thickness, max_thickness = 0.0025, 0.75\n",
    "min_weight, max_weight = min(edge_weights), max(edge_weights)\n",
    "threshold_1 = 100000  # Start of steep outliers\n",
    "threshold_2 = 7000    # Flatten smaller values below this\n",
    "\n",
    "# Compress weights.\n",
    "def transform_weight(weight):\n",
    "    if weight > threshold_1:\n",
    "        # Heavy punishment for extreme amounts.\n",
    "        return np.log1p(weight) / np.log1p(max_weight)\n",
    "    elif weight > threshold_2:\n",
    "        # Moderate punishment for moderate amounts.\n",
    "        return (weight - threshold_2) / (threshold_1 - threshold_2)\n",
    "    else:\n",
    "        # Linear scaling for miniscule amounts.\n",
    "        return (weight - min_weight) / (threshold_2 - min_weight)\n",
    "\n",
    "# Normalize weights with piecewise scaling\n",
    "normalized_weights = [transform_weight(weight) for weight in edge_weights]\n",
    "\n",
    "# Exponent < 1 reduces larger values more\n",
    "normalized_weights = [weight ** 0.5 for weight in normalized_weights]  \n",
    "\n",
    "# Scale normalized weights to the thickness range\n",
    "edge_widths = [min_thickness + (max_thickness - min_thickness) * weight for weight in normalized_weights]\n",
    "\n",
    "# Node pac-to-candidate transaction attributes.\n",
    "for index, row in df_candpacs_to_pactrans.iterrows():\n",
    "    # Party info\n",
    "    G.nodes[row['ultorg__cand_cmtes18']]['party__cands18'] = row['party__cands18']\n",
    "    G.nodes[row['ultorg__noncand_cmtes18']]['party__cands18'] = G.nodes[row['ultorg__noncand_cmtes18']].get('party__cands18', None) # Why is this here?\n",
    "    # Link contributor non-candidate pacs to candidate pacs.\n",
    "    G.nodes[row['ultorg__noncand_cmtes18']]['recipcode__noncand_cmtes18'] = row['recipcode__noncand_cmtes18']\n",
    "\n",
    "# Add [co]sponsored bills attributes.\n",
    "for index, row in df_wm_candspons_bills.iterrows():\n",
    "    # Party info\n",
    "    G.nodes[row['number']]['party__cands18'] = row['party__cands18']\n",
    "\n",
    "# Party colors.\n",
    "color_map = []\n",
    "for node in G.nodes(data=True):\n",
    "    if node[1].get('party__cands18') == 'D':\n",
    "        color_map.append('skyblue')\n",
    "    elif node[1].get('party__cands18') == 'R':\n",
    "        color_map.append('lightcoral')\n",
    "    elif node[1].get('recipcode__noncand_cmtes18') == 'PB':\n",
    "        color_map.append('#cc00cc')\n",
    "    elif node[1].get('recipcode__noncand_cmtes18') == 'PL':\n",
    "        color_map.append('#33cc33')\n",
    "    elif node[1].get('recipcode__noncand_cmtes18') == 'PI':\n",
    "        color_map.append('#ff9900')\n",
    "    elif node[1].get('recipcode__noncand_cmtes18') == 'OB':\n",
    "        color_map.append('#ff66ff')\n",
    "    elif node[1].get('recipcode__noncand_cmtes18') == 'OL':\n",
    "        color_map.append('#99ff99')\n",
    "    elif node[1].get('recipcode__noncand_cmtes18') == 'OI':\n",
    "        color_map.append('#ffcc66')\n",
    "    else:\n",
    "        color_map.append('gray')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DISPLAY GRAPH\n",
    "# ============================================================\n",
    "\n",
    "layouts = {\n",
    "    # \"random\": nx.random_layout,\n",
    "    # \"spring\": nx.spring_layout,\n",
    "    \"kamada_kawai\": nx.kamada_kawai_layout,\n",
    "    # \"graphviz\": nx.nx_agraph.graphviz_layout,\n",
    "    # \"circular\": nx.circular_layout,\n",
    "    # \"spectral\": nx.spectral_layout,\n",
    "}\n",
    "\n",
    "# Calculate node sizes\n",
    "node_sizes = {}\n",
    "\n",
    "# Size PAC nodes (contributors) based on total amount contributed\n",
    "for node in G.nodes():\n",
    "    total_contribution = sum(\n",
    "        data['amount__pacs18'] for _, target, data in G.edges(node, data=True) if 'amount__pacs18' in data\n",
    "    )\n",
    "    # Scale the size (adjust scaling factor as needed)\n",
    "    node_sizes[node] = 100 + 10 * np.sqrt(total_contribution)  # Example scaling\n",
    "\n",
    "for node in G.nodes():\n",
    "    if node not in node_sizes:\n",
    "        node_sizes[node] = 300  # Default size for unmatched nodes\n",
    "\n",
    "# For graphviz_layout:\n",
    "# $ brew install graphviz (bash terminal)\n",
    "# conda install -c conda-forge pygraphviz (in notebook cell)\n",
    "# pip install pydot (in notebook cell)\n",
    "\n",
    "for layout_name, layout_func in layouts.items():\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    \n",
    "    if layout_name == 'nx_agraph.graphviz_layout':\n",
    "        pos = layout_func(G, prog='dot')\n",
    "    else:\n",
    "        pos = layout_func(G)\n",
    "\n",
    "    degrees = dict(G.degree())\n",
    "    sorted_nodes = sorted(G.nodes, key=lambda x: degrees[x]) # high degree nodes in front\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=False, node_color=color_map, font_size=7, font_color=\"black\",\n",
    "            width=edge_widths, node_size=[node_sizes.get(node, 300) for node in G.nodes()], bbox=dict(facecolor='white', edgecolor='black',\n",
    "            boxstyle='round,pad=0.3')) # node_size=[node_sizes[node] for node in G.nodes()]\n",
    "\n",
    "    # Only PAC to Candidate PAC edges have a weight derived from the amount field.\n",
    "    # edge_labels = {\n",
    "    #     (u, v): f\"{d['amount__pacs18']}\"\n",
    "    #     for u, v, d in G.edges(data=True)\n",
    "    #     if 'amount__pacs18' in d\n",
    "    # }\n",
    "    # nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=5)\n",
    "    \n",
    "    plt.title(\"PACs to Candidates â€“Â \" + layout_name + \" layout\", fontsize=50)\n",
    "    plt.savefig('../../outputs/viz_' + layout_name + '.png', format='png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447268e-3137-44e8-8cdb-98f2eeb344f3",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935c558-5e3d-4b06-9324-082cd4c23a32",
   "metadata": {},
   "source": [
    "### Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014c6cc-25d2-405c-b42a-69a005943320",
   "metadata": {},
   "source": [
    "For beggining an exploration of which features and patterns might be useful for making predictions or finding other insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66711a04-873d-49c7-b5bd-aab56237250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global clustering coefficient\n",
    "# (ratio of closed triplets to triplets)\n",
    "print(\"Transitivity:\", nx.transitivity(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a5692-0907-4396-bf56-a2d63d0b59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global clustering coefficient\n",
    "print(\"Global Clustering Coefficient:\", nx.transitivity(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbaedbc-9305-4da2-b8c9-d58f4f87e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average clustering coefficient\n",
    "print(\"Average Clustering Coefficient:\", nx.average_clustering(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c426d3b-ff5f-4561-a2a2-98e6e7537c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of possible edges\n",
    "print(\"Density:\", round(nx.density(G), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f393e1-5a5d-4b5e-9dd0-8d450fbfeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network diameter.\n",
    "if nx.is_connected(G):\n",
    "    print(\"Diameter:\", nx.diameter(G))\n",
    "else:\n",
    "    print(\"Graph is not connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb950d-bddb-4dc6-a5ae-f7ebaeb08477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average path length\n",
    "if nx.is_connected(G):\n",
    "    print(\"Average Path Length:\", round(nx.average_shortest_path_length(G), 3))\n",
    "else:\n",
    "    print(\"Graph is not connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9d480-4347-4a25-93ed-7608d2587119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node with the minimum eccentricity.\n",
    "if nx.is_connected(G):\n",
    "    print(\"Radius:\", nx.radius(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1531aba-c717-43cf-a4d4-12bad339b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of triangles\n",
    "print(\"Total Triangles:\", sum(nx.triangles(G).values()) // 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787a15e-fd30-4d37-9581-39afafab3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assortativity coefficient\n",
    "print(\"Assortativity Coefficient:\", round(nx.degree_assortativity_coefficient(G), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113777fb-b4aa-4243-90f4-24e6a41dd98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected components\n",
    "print(\"Connected Components:\", len(list(nx.connected_components(G))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd928d-9baa-4922-8a2a-a3bd98285c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge connectivity\n",
    "# Minimum number of edges that need to be removed to disconnect the graph.\n",
    "print(\"Edge Connectivity:\", nx.edge_connectivity(G))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92eb33ff-ff3c-4bc8-85aa-ee45c7a9785c",
   "metadata": {},
   "source": [
    "### Contribution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2544ef2-cb13-4e71-bd87-f14cd3053867",
   "metadata": {},
   "source": [
    "#### Fundraising figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f7fb1-5f16-4b40-8133-17525bf9bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num contributions\n",
    "print(f\"Overall, members received {len(df_full_network['amount__pacs18']):,} contributions\")\n",
    "print(f\"Democrats received {len(df_full_network[df_full_network['party__cands18'] == 'D']):,} contributions\")\n",
    "print(f\"Democrats received {len(df_full_network[df_full_network['party__cands18'] == 'R']):,} contributions\")\n",
    "print(f\"All others received {len(df_full_network[(df_full_network['party__cands18'] == 'D') & (df_full_network['party__cands18'] == 'R')]):,} contributions\")\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "# Money raised\n",
    "print(f\"Overall, members raised ${df_full_network['amount__pacs18'].sum():,}\")\n",
    "print(f\"Democrats raised ${df_full_network[df_full_network['party__cands18'] == 'D']['amount__pacs18'].sum():,}\")\n",
    "print(f\"Republicans raised ${df_full_network[df_full_network['party__cands18'] == 'R']['amount__pacs18'].sum():,}\")\n",
    "print(f\"All others raised ${df_full_network[(df_full_network['party__cands18'] != 'D') & (df_full_network['party__cands18'] != 'R')]['amount__pacs18'].sum():,}\")\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "# Averages\n",
    "print(f\"Overall, members raised ${round(df_full_network['amount__pacs18'].sum()/len(df_full_network), 2):,} on average\")\n",
    "print(f\"Democrats raised ${round(df_full_network[df_full_network['party__cands18'] == 'D']['amount__pacs18'].sum()/len(df_full_network[df_full_network['party__cands18'] == 'D']), 2):,} on average\")\n",
    "print(f\"Republicans raised ${round(df_full_network[df_full_network['party__cands18'] == 'R']['amount__pacs18'].sum()/len(df_full_network[df_full_network['party__cands18'] == 'R']), 2):,} on average\")\n",
    "print(f\"All other raised $0 on average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05a0f7-4c28-400f-910d-13388c000889",
   "metadata": {},
   "source": [
    "Extreme outliers are present. For example, Steven Horsford (running for an open seat) has a single, massive \\\\$2,663,800 donation that vastly overwhelms other transactions. After that, Vern Buchanan has a rather large \\\\$588,015 donation. Transactions eventually settle at around \\\\$5,000 per contribution after the first 155 contributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9243d83-c55f-41c0-9928-1a18fd91bef4",
   "metadata": {},
   "source": [
    "#### Distribution of contributions\n",
    "Earnings are extremely right-skewed before it the curve goes linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51e603-2eec-4d8b-9f8d-732bb92d859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_amounts = df_full_network.copy()\n",
    "df_all_amounts = df_all_amounts.sort_values(by='amount__pacs18', ascending=False)\n",
    "df_all_amounts = df_all_amounts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ada02-08eb-4118-8caa-be27ee44e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "showdf(df_all_amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d2bd8-86c3-49fa-9686-19eb64705055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Format ticks as dollars.\n",
    "def dollar_formatter(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "axes[0].plot(df_all_amounts.index[:10], df_all_amounts['amount__pacs18'][:10])\n",
    "axes[0].set_xlabel('Num of individual contributions')\n",
    "axes[0].set_ylabel('Contribution dollar amount')\n",
    "axes[0].set_title('Top 10 contributions')\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(dollar_formatter))\n",
    "\n",
    "axes[1].plot(df_all_amounts.index[:50], df_all_amounts['amount__pacs18'][:50])\n",
    "axes[1].set_xlabel('Num of individual contributions')\n",
    "axes[1].set_ylabel('Contribution dollar amount')\n",
    "axes[1].set_title('Top 50 contributions')\n",
    "axes[1].yaxis.set_major_formatter(FuncFormatter(dollar_formatter))\n",
    "\n",
    "axes[2].plot(df_all_amounts.index[:500], df_all_amounts['amount__pacs18'][:500])  # Same plot for demonstration\n",
    "axes[2].set_xlabel('Num of individual contributions')\n",
    "axes[2].set_ylabel('Contribution dollar amount')\n",
    "axes[2].set_title('Top 500 contributions')\n",
    "axes[2].yaxis.set_major_formatter(FuncFormatter(dollar_formatter))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b00fd6-6e90-4ace-a8aa-c762fb27647a",
   "metadata": {},
   "source": [
    "#### Top recipients\n",
    "Receipts represent all PAC to Candidate transfers, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d3abb-b5ff-4971-b8a5-69d0bbd3faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at this thing.\n",
    "df_all_amounts = df_graph_network.sort_values(by='amount__pacs18', ascending=False).reset_index(drop=True)\n",
    "print(f\"Number of transactions:\\n{len(df_all_amounts)}\\n\")\n",
    "print(f\"Seems the top earner is going for an open seat!\\n\")\n",
    "print(f\"The five earners are:\\n{df_all_amounts['ultorg__cand_cmtes18'].unique()[:10]}\\n\")\n",
    "df_top_amounts = df_all_amounts.sort_values(by='amount__pacs18')[['amount__pacs18']].reset_index(drop=True)\n",
    "print(f\"The largest contribution:\\n{df_top_amounts['amount__pacs18'].max()}\\n\")\n",
    "print(f\"The top ten largest contributions:\\n{df_top_amounts.nlargest(10, 'amount__pacs18')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
